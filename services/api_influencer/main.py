from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import os
import json
import re
import hashlib

app = FastAPI()

import utils.shared as shared


class InfluencerRequest(BaseModel):
    user_text: str
    influencer_name: Optional[str] = None
    user_nickname: Optional[str] = None
    conversation_history: Optional[List[Dict[str, Any]]] = None
    emotion_meta: Optional[Dict[str, Any]] = None


class InfluencerListItem(BaseModel):
    id: Optional[str] = None
    name: str
    short_description: Optional[str] = None
    example_sentences: Optional[List[str]] = None


class InfluencerApplyResponse(BaseModel):
    influencer: str
    styled_text: str
    raw: Optional[Dict[str, Any]] = None


def _extract_json_from_text(text: str):
    m = re.search(r"\{.*\}", text, re.S)
    if not m:
        return None
    s = m.group(0)
    try:
        return json.loads(s)
    except Exception:
        return None


def load_influencers_from_excel(path: str):
    # Try to load with pandas/openpyxl, gracefully fallback to built-ins
    try:
        import pandas as pd
        df = pd.read_excel(path)
        items = []
        for _, row in df.iterrows():
            name = str(row.get('name') or row.get('Name') or row.get('ì´ë¦„') or '')
            short = row.get('short_description') or row.get('short') or row.get('ì„¤ëª…') or ''
            examples = row.get('example_sentences') or row.get('examples') or row.get('ì˜ˆì‹œ') or ''
            if isinstance(examples, str):
                examples_list = [s.strip() for s in re.split(r"[\n;]\s*", examples) if s.strip()]
            elif isinstance(examples, (list, tuple)):
                examples_list = list(examples)
            else:
                examples_list = []
            if name:
                items.append({
                    'name': name,
                    'short_description': str(short) if short else None,
                    'example_sentences': examples_list,
                })
        return items
    except Exception:
        # fallback static influencers
        return [
            {'name': 'ì›ì¤€', 'short_description': 'ì¹œê·¼í•˜ë©´ì„œë„ ì†”ì§í•œ ë¦¬ë·°', 'example_sentences': ['ì•ˆë…•í•˜ì„¸ìš” ê·€ìš¤ì´ë‹˜! ì›ì¤€ì…ë‹ˆë‹¤!', 'ì •ë§ ì´ê±´ ì¶”ì²œí•´ìš”.']},
            {'name': 'ì„¸í˜„', 'short_description': 'ìì—°ìŠ¤ëŸ¬ìš´ ë°ì¼ë¦¬ ë©”ì´í¬ì—… ì „ë¬¸', 'example_sentences': ['ì•ˆë…•í•˜ì„¸ìš” í¬ë“œë˜ê³¤ë‹˜! ì„¸í˜„ì´ì˜ˆìš”!', 'ì‚´ì§ë§Œ ë°œë¼ë„ ì˜ˆë»ìš”.']},
            {'name': 'ì¢…ë¯¼', 'short_description': 'ê°€ì„±ë¹„ ì¤‘ì‹¬ì˜ ì‹¤ìš©ì  ë¦¬ë·°', 'example_sentences': ['ì•ˆë…•í•˜ì„¸ìš” íŠ¸ë£¨ë“œë˜ê³¤ë‹˜! ì¢…ë¯¼ì…ë‹ˆë‹¤!', 'ê°€ì„±ë¹„ ì¢‹ê³  ì‹¤ìš©ì ì´ì—ìš”.']},
            {'name': 'í˜œê²½', 'short_description': 'ì¢…í•© ë·°í‹° ê°€ì´ë“œ', 'example_sentences': ['ì•ˆë…•í•˜ì„¸ìš” ë·°í‹°íŒ¨ë°€ë¦¬ë‹˜! í˜œê²½ì…ë‹ˆë‹¤!', 'ìƒí™©ì— ë§ê²Œ ì¶”ì²œë“œë ¤ìš”.']},
        ]


# load influencers once
_INFLUENCERS_PATH = os.path.join(os.getcwd(), 'popular_youtubers.xlsx')
_INFLUENCERS = load_influencers_from_excel(_INFLUENCERS_PATH) if os.path.exists(_INFLUENCERS_PATH) else load_influencers_from_excel('')


def make_id(n: str) -> str:
    """Create a stable slug-like id from a name.

    - Preserve Unicode word characters (so Korean names remain readable).
    - Replace spaces with underscore and strip extra underscores/hyphens.
    - If resulting slug is empty, fall back to a stable short hash.
    """
    try:
        s = (n or '').strip().lower().replace(' ', '_')
        s = re.sub(r"[^\w\-]", '', s, flags=re.UNICODE)
        s = re.sub(r'_+', '_', s).strip('_-')
        if not s:
            s = hashlib.sha1((n or '').encode('utf-8')).hexdigest()[:8]
        return s
    except Exception:
        return hashlib.sha1((n or '').encode('utf-8')).hexdigest()[:8]


# Ensure loaded influencer list items include a stable `id` field
for it in _INFLUENCERS:
    try:
        it.setdefault('id', make_id(it.get('name', '')))
    except Exception:
        # best-effort; don't crash module import
        it.setdefault('id', hashlib.sha1(repr(it).encode('utf-8')).hexdigest()[:8])

@app.get('/api/influencer/list', response_model=List[InfluencerListItem])
def list_influencers():
    return _INFLUENCERS


@app.post('/api/influencer/apply', response_model=InfluencerApplyResponse)
def apply_influencer_style(payload: InfluencerRequest):
    if not payload or not payload.user_text:
        raise HTTPException(status_code=400, detail='user_textê°€ í•„ìš”í•©ë‹ˆë‹¤')

    # choose influencer if explicitly provided; do NOT auto-assign a default
    influencer = None
    if payload.influencer_name:
        for it in _INFLUENCERS:
            if it['name'].strip().lower() == payload.influencer_name.strip().lower():
                influencer = it
                break
    # If influencer is not provided or not found, proceed without applying a persona
    # (neutral behavior) rather than falling back to the first influencer.

    # build system prompt with influencer persona if available
    if influencer:
        persona = influencer.get('short_description') or ''
        examples = '\n'.join(influencer.get('example_sentences') or [])
        system_prompt = f"""
ë‹¹ì‹ ì€ ë‹¤ìŒ ì¸í”Œë£¨ì–¸ì„œì˜ ë§íˆ¬ë¡œ ë‹µë³€í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
ì¸í”Œë£¨ì–¸ì„œ: {influencer['name']}
ì„¤ëª…: {persona}
ì˜ˆì‹œ ë¬¸ì¥:
{examples}
"""
    else:
        # neutral advisor system prompt when no influencer persona is requested
        system_prompt = "ë‹¹ì‹ ì€ í¼ìŠ¤ë„ì»¬ëŸ¬ ë° ë·°í‹° ë¶„ì•¼ì— ì¹œì ˆí•œ ìƒë‹´ìì…ë‹ˆë‹¤. ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ ì–´ì¡°ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”."

    # Build user content including emotion metadata if provided
    emotion_block = ''
    if payload.emotion_meta:
        emotion_block = json.dumps(payload.emotion_meta, ensure_ascii=False)

    # Determine salutation: use provided user_nickname (append 'ë‹˜'), otherwise use influencer subscriber default
    salutation = None
    try:
        profile = YOUTUBER_PROFILES.get(influencer['name'], {})
        subs = profile.get('subscriber_name') or []
        default_sub = subs[0] if isinstance(subs, (list, tuple)) and len(subs) > 0 else 'ì—¬ëŸ¬ë¶„'
    except Exception:
        default_sub = 'ì—¬ëŸ¬ë¶„'

    if getattr(payload, 'user_nickname', None):
        salutation = f"{payload.user_nickname}ë‹˜"
    else:
        salutation = default_sub

    user_content = f"í˜¸ì¹­: {salutation}\nì‚¬ìš©ì ìš”ì²­: {payload.user_text}\nê°ì • ë©”íƒ€: {emotion_block}\nëŒ€í™” ë§¥ë½:\n"
    if payload.conversation_history:
        user_content += '\n'.join([m.get('text') or m.get('message') or '' for m in payload.conversation_history[-10:]])

    # Ask model to return a single JSON with styled_text
    json_instructions = (
        "\n\nì¤‘ìš”: ì„¤ëª… ì—†ì´ ë‹¨ í•˜ë‚˜ì˜ ìœ íš¨í•œ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ì„¸ìš”. JSONì˜ í‚¤: styled_text (ë¬¸ìì—´)."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content + json_instructions},
    ]

    try:
        resp = shared.client.chat.completions.create(
            model=os.getenv('DEFAULT_MODEL') or 'gpt-4o-mini',
            messages=messages,
            temperature=0.6,
            max_tokens=400,
        )
    except Exception as e:
        raise HTTPException(status_code=502, detail=f'Upstream model error: {e}')

    # extract content
    content = None
    if resp and getattr(resp, 'choices', None):
        ch = resp.choices[0]
        if isinstance(ch, dict):
            content = ch.get('message', {}).get('content') or ch.get('text')
        else:
            content = getattr(ch.message, 'content', None) or getattr(ch, 'text', None)

    if not content:
        raise HTTPException(status_code=500, detail='Empty model response')

    parsed = _extract_json_from_text(content)
    if not parsed:
        # try whole content
        try:
            parsed = json.loads(content)
        except Exception:
            # fallback: treat entire text as styled_text
            return InfluencerApplyResponse(influencer=(influencer.get('name') if influencer else ''), styled_text=content.strip(), raw={'model_output': content})

    styled = parsed.get('styled_text') or parsed.get('text') or parsed.get('response') or ''
    return InfluencerApplyResponse(influencer=(influencer.get('name') if influencer else ''), styled_text=styled, raw={'model_output': parsed})


# --- ì¶”ê°€: ê°•í™”ëœ ìœ íŠœë²„ í”„ë¡œí•„ ë° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì›ì¤€, ì„¸í˜„, ì¢…ë¯¼, í˜œê²½) ---
YOUTUBER_PROFILES = {
    'ì›ì¤€': {
        'greeting': 'ì•ˆë…•í•˜ì„¸ìš” ê·€ìš¤ì´ë‹˜! ì›ì¤€ì…ë‹ˆë‹¤!',
        'emoji': 'ğŸŒŸ',
        'color': '#FFE4E6',
        'icon': 'ğŸ‘‘',
        'subscriber_name': ['ë·°í‹°ëŸ¬ë²„', 'ê·€ìš¤ì´'],
        'signature_expressions': ['ì •ë§', 'ì†”ì§íˆ', 'ì™„ì „', 'ê°œì¸ì ìœ¼ë¡œ', 'ì§„ì§œ'],
        'closing': 'ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!',
        'characteristics': 'ì¹œê·¼í•˜ë©´ì„œë„ ì†”ì§í•œ í‰ê°€, ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì „ë¬¸ ë¦¬ë·°',
        'speaking_style': 'ì¹œê·¼í•˜ì§€ë§Œ ì „ë¬¸ì ì¸ í†¤, ë¯¿ì„ ìˆ˜ ìˆëŠ” ì–¸ë‹ˆ ëŠë‚Œ',
        'expertise': ['ì´ˆë³´ì ì¹œí™”ì ', 'ì†”ì§í•œ ì œí’ˆ ë¦¬ë·°'],
        'strengths': ['friendliness', 'honesty', 'beginner_friendly']
    },
    'ì„¸í˜„': {
        'greeting': 'ì•ˆë…•í•˜ì„¸ìš” í¬ë“œë˜ê³¤ë‹˜! ì„¸í˜„ì´ì˜ˆìš”!',
        'emoji': 'ğŸŒ¿',
        'color': '#E8F5E8',
        'icon': 'ğŸƒ',
        'subscriber_name': ['í¬ë“œë˜ê³¤'],
        'signature_expressions': ['ì‚´ì§', 'ìì—°ìŠ¤ëŸ½ê²Œ', 'ì™„ì „', 'ë„ˆë¬´', 'ì¢€'],
        'closing': 'ìì—°ìŠ¤ëŸ¬ìš´ ì•„ë¦„ë‹¤ì›€ìœ¼ë¡œ ë” ë¹›ë‚˜ì„¸ìš”! êµ¬ë… ì¢‹ì•„ìš”!',
        'characteristics': 'ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ì„¤ëª…, í”¼ë¶€ì™€ ë°ì¼ë¦¬ ë©”ì´í¬ì—… ì „ë¬¸',
        'speaking_style': 'ì°¨ë¶„í•˜ë©´ì„œ ì¹œê·¼í•œ í†¤, ìì—°ìŠ¤ëŸ¬ìš´ ì–¸ë‹ˆ ëŠë‚Œ',
        'expertise': ['ìì—°ìŠ¤ëŸ¬ìš´ ë©”ì´í¬ì—…', 'ì´ˆë³´ì ê°€ì´ë“œ'],
        'strengths': ['naturalness', 'friendliness', 'skin_focus']
    },
    'ì¢…ë¯¼': {
        'greeting': 'ì•ˆë…•í•˜ì„¸ìš” íŠ¸ë£¨ë“œë˜ê³¤ë‹˜! ì¢…ë¯¼ì…ë‹ˆë‹¤!',
        'emoji': 'ğŸ’°',
        'color': '#FFF2CC',
        'icon': 'ğŸ’',
        'subscriber_name': ['íŠ¸ë£¨ë“œë˜ê³¤', 'ê°€ì„±ë¹„ëŸ¬ë²„'],
        'signature_expressions': ['ì†”ì§íˆ', 'ê°œì¸ì ìœ¼ë¡œ', 'ì‚´ì§', 'ê°€ì„±ë¹„', 'ì¶”ì²œ'],
        'closing': 'ê°€ì„±ë¹„ ìµœê³  ì œí’ˆë“¤ë¡œ ì˜ˆë»ì§€ì„¸ìš”! íŠ¸ë£¨ë“œë˜ê³¤ë‹˜ ê°ì‚¬í•´ìš”!',
        'characteristics': 'ì†”ì§í•œ ì œí’ˆ ë¶„ì„ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ ì‚¬ìš©ë²•, ê°€ì„±ë¹„ ì¤‘ì‹¬ ë¦¬ë·°',
        'speaking_style': 'ì†”ì§í•˜ë©´ì„œ í¸ì•ˆí•œ í†¤, ì‹¤ìš©ì ì¸ ì¡°ì–¸',
        'expertise': ['ê°€ì„±ë¹„ ì œí’ˆ ë¶„ì„', 'ìì—°ìŠ¤ëŸ¬ìš´ í™œìš©ë²•'],
        'strengths': ['product_analysis', 'cost_effectiveness', 'naturalness']
    },
    'í˜œê²½': {
        'greeting': 'ì•ˆë…•í•˜ì„¸ìš” ë·°í‹°íŒ¨ë°€ë¦¬ë‹˜! í˜œê²½ì…ë‹ˆë‹¤!',
        'emoji': 'ğŸ¨',
        'color': '#F0E6FF',
        'icon': 'ğŸª',
        'subscriber_name': ['ë·°í‹°íŒ¨ë°€ë¦¬'],
        'signature_expressions': ['ì •ë§', 'ì†”ì§íˆ', 'ìì—°ìŠ¤ëŸ½ê²Œ', 'ì™„ì „', 'ê°œì¸ì ìœ¼ë¡œ'],
        'closing': 'ë·°í‹°íŒ¨ë°€ë¦¬ ëª¨ë‘ ì˜ˆë»ì§€ì„¸ìš”! êµ¬ë… ì¢‹ì•„ìš” ê°ì‚¬í•©ë‹ˆë‹¤!',
        'characteristics': 'ì¹œê·¼í•˜ê³  ì†”ì§í•˜ë©° ìì—°ìŠ¤ëŸ¬ìš´ ì¢…í•© ë·°í‹° ê°€ì´ë“œ',
        'speaking_style': 'ëª¨ë“  ë§¤ë ¥ì„ ì¡°í™”ë¡­ê²Œ ì„ì€ ì™„ë²½í•œ í†¤',
        'expertise': ['ì´ˆë³´ì ê°€ì´ë“œ', 'ì œí’ˆ ë¦¬ë·°', 'ìì—°ìŠ¤ëŸ¬ìš´ ë©”ì´í¬ì—…'],
        'strengths': ['friendliness', 'honesty', 'naturalness', 'comprehensive']
    }
}


@app.get('/api/influencer/profiles')
def influencer_profiles():
    """Return enriched influencer profile objects for frontend consumption."""
    out = []
    for name, meta in YOUTUBER_PROFILES.items():
        # shallow copy to avoid accidental mutation
        m = dict(meta or {})
        obj = {**m, 'name': name}
        # ensure stable id
        obj.setdefault('id', make_id(name))

        # Normalize types and ensure fields expected by frontend InfluencerProfile exist
        # greeting, emoji, color, subscriber_name (list), closing, characteristics, expertise (list)
        try:
            if not isinstance(obj.get('greeting'), str):
                obj['greeting'] = obj.get('greeting') or ''
            if not isinstance(obj.get('emoji'), str):
                obj['emoji'] = obj.get('emoji') or ''
            if not isinstance(obj.get('color'), str):
                obj['color'] = obj.get('color') or '#ffffff'
            # subscriber_name should be an array of strings
            subs = obj.get('subscriber_name') or obj.get('subscriber_names') or []
            if isinstance(subs, str):
                subs = [s.strip() for s in re.split(r'[;,\n]+', subs) if s.strip()]
            if not isinstance(subs, list):
                subs = list(subs) if subs else []
            obj['subscriber_name'] = subs

            if not isinstance(obj.get('closing'), str):
                obj['closing'] = obj.get('closing') or ''
            if not isinstance(obj.get('characteristics'), str):
                obj['characteristics'] = obj.get('characteristics') or ''
            ex = obj.get('expertise') or obj.get('expertises') or []
            if isinstance(ex, str):
                ex = [s.strip() for s in re.split(r'[;,\n]+', ex) if s.strip()]
            if not isinstance(ex, list):
                ex = list(ex) if ex else []
            obj['expertise'] = ex
        except Exception:
            # best-effort normalization; ignore failures
            obj.setdefault('greeting', '')
            obj.setdefault('emoji', '')
            obj.setdefault('color', '#ffffff')
            obj.setdefault('subscriber_name', [])
            obj.setdefault('closing', '')
            obj.setdefault('characteristics', '')
            obj.setdefault('expertise', [])

        out.append(obj)
    return out

SYSTEM_PROMPTS = {
    'ì›ì¤€': """ë‹¹ì‹ ì€ ê°€ìƒ ì¸í”Œë£¨ì–¸ì„œ 'ì›ì¤€'ì˜ ë©”ì´í¬ì—… ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì¤‘ìš”: ì˜¤ì§ ë©”ì´í¬ì—…, ë·°í‹°, ìŠ¤í‚¨ì¼€ì–´ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ì„¸ìš”. ë‹¤ë¥¸ ì£¼ì œëŠ” ì ˆëŒ€ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”.
ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:
1. ì¸ì‚¬ë§: ë°˜ë“œì‹œ "ì•ˆë…•í•˜ì„¸ìš” ê·€ìš¤ì´ë‹˜! ì›ì¤€ì…ë‹ˆë‹¤!"ë¡œ ì‹œì‘í•˜ì„¸ìš”
2. ì¹œê·¼í•¨(ì •ë§, ì™„ì „)ê³¼ ì†”ì§í•¨(ì†”ì§íˆ, ê°œì¸ì ìœ¼ë¡œ)ì„ ì¡°í™”ë¡­ê²Œ ì‚¬ìš©í•˜ì„¸ìš”
3. ì´ˆë³´ìë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹¨ê³„ë³„ ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”
4. ë§ˆë¬´ë¦¬ëŠ” "ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? ë” ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”!"ë¡œ ëë‚´ì„¸ìš”
""",
    'ì„¸í˜„': """ë‹¹ì‹ ì€ ê°€ìƒ ì¸í”Œë£¨ì–¸ì„œ 'ì„¸í˜„'ì˜ ë©”ì´í¬ì—… ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì¤‘ìš”: ì˜¤ì§ ë©”ì´í¬ì—…, ë·°í‹°, ìŠ¤í‚¨ì¼€ì–´ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ì„¸ìš”.
ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:
1. ì¸ì‚¬ë§: ë°˜ë“œì‹œ "ì•ˆë…•í•˜ì„¸ìš” í¬ë“œë˜ê³¤ë‹˜! ì„¸í˜„ì´ì˜ˆìš”!"ë¡œ ì‹œì‘í•˜ì„¸ìš”
2. ìì—°ìŠ¤ëŸ½ê³  ì°¨ë¶„í•œ í†¤ ìœ ì§€(ì‚´ì§, ìì—°ìŠ¤ëŸ½ê²Œ)
3. ë°ì¼ë¦¬ ë©”ì´í¬ì—…ê³¼ í”¼ë¶€ ì¼€ì–´ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
4. ë§ˆë¬´ë¦¬ëŠ” "ìì—°ìŠ¤ëŸ¬ìš´ ì•„ë¦„ë‹¤ì›€ìœ¼ë¡œ ë” ë¹›ë‚˜ì„¸ìš”!"ë¡œ ëë‚´ì„¸ìš”
""",
    'ì¢…ë¯¼': """ë‹¹ì‹ ì€ ê°€ìƒ ì¸í”Œë£¨ì–¸ì„œ 'ì¢…ë¯¼'ì˜ ë©”ì´í¬ì—… ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì¤‘ìš”: ì˜¤ì§ ë©”ì´í¬ì—…, ë·°í‹°, ìŠ¤í‚¨ì¼€ì–´ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ì„¸ìš”.
ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:
1. ì¸ì‚¬ë§: ë°˜ë“œì‹œ "ì•ˆë…•í•˜ì„¸ìš” íŠ¸ë£¨ë“œë˜ê³¤ë‹˜! ì¢…ë¯¼ì…ë‹ˆë‹¤!"ë¡œ ì‹œì‘í•˜ì„¸ìš”
2. ì†”ì§í•˜ê³  ì‹¤ìš©ì ì¸ ê°€ì„±ë¹„ ì¤‘ì‹¬ì˜ ì„¤ëª… ì œê³µ
3. ì œí’ˆì˜ ì¥ë‹¨ì ê³¼ ê°€ê²©ëŒ€ë³„ ì¶”ì²œ í¬í•¨
4. ë§ˆë¬´ë¦¬ëŠ” "ê°€ì„±ë¹„ ìµœê³  ì œí’ˆë“¤ë¡œ ì˜ˆë»ì§€ì„¸ìš”! íŠ¸ë£¨ë“œë˜ê³¤ë‹˜ ê°ì‚¬í•´ìš”!"ë¡œ ëë‚´ì„¸ìš”
""",
    'í˜œê²½': """ë‹¹ì‹ ì€ ê°€ìƒ ì¸í”Œë£¨ì–¸ì„œ 'í˜œê²½'ì˜ ë©”ì´í¬ì—… ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì¤‘ìš”: ì˜¤ì§ ë©”ì´í¬ì—…, ë·°í‹°, ìŠ¤í‚¨ì¼€ì–´ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ì„¸ìš”.
ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:
1. ì¸ì‚¬ë§: ë°˜ë“œì‹œ "ì•ˆë…•í•˜ì„¸ìš” ë·°í‹°íŒ¨ë°€ë¦¬ë‹˜! í˜œê²½ì…ë‹ˆë‹¤!"ë¡œ ì‹œì‘í•˜ì„¸ìš”
2. ì¹œê·¼í•¨ê³¼ ì†”ì§í•¨, ìì—°ìŠ¤ëŸ¬ì›€ì„ ê· í˜•ìˆê²Œ ì‚¬ìš©í•˜ì„¸ìš”
3. ì´ˆë³´ì ê°€ì´ë“œ + ì œí’ˆ ë¦¬ë·° + ìì—°ìŠ¤ëŸ¬ìš´ ë©”ì´í¬ì—…ì„ í¬í•¨í•˜ì„¸ìš”
4. ë§ˆë¬´ë¦¬ëŠ” "ë·°í‹°íŒ¨ë°€ë¦¬ ëª¨ë‘ ì˜ˆë»ì§€ì„¸ìš”! ê°ì‚¬í•©ë‹ˆë‹¤!"ë¡œ ëë‚´ì„¸ìš”
""",
}


# Endpoint: api_emotionì˜ ì¶œë ¥(JSON)ì„ ë°›ì•„ í•´ë‹¹ ì¸í”Œë£¨ì–¸ì„œ ë§íˆ¬ë¡œ ì¬ì‘ì„±
class EmotionChainRequest(BaseModel):
    emotion_result: Dict[str, Any]
    # allow passing color_result so influencer can weave color recommendations
    color_result: Optional[Dict[str, Any]] = None
    influencer_name: Optional[str] = None
    user_nickname: Optional[str] = None


class EmotionChainResponse(BaseModel):
    influencer: str
    styled_text: str
    raw: Optional[Dict[str, Any]] = None


@app.post('/api/influencer/style_emotion', response_model=EmotionChainResponse)
def style_emotion_chain(payload: EmotionChainRequest):
    # pick influencer only if explicitly provided and allowed
    allowed = ['ì›ì¤€', 'ì„¸í˜„', 'ì¢…ë¯¼', 'í˜œê²½']
    influencer = payload.influencer_name if payload.influencer_name in allowed else None

    # Use influencer-specific system prompt only when influencer is provided.
    # Otherwise use a neutral advisor prompt (no persona).
    if influencer:
        system_prompt = SYSTEM_PROMPTS.get(influencer, '')
    else:
        system_prompt = "ë‹¹ì‹ ì€ í¼ìŠ¤ë„ì»¬ëŸ¬ ë° ë·°í‹° ë¶„ì•¼ì— ì¹œì ˆí•œ ìƒë‹´ìì…ë‹ˆë‹¤. ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ ì–´ì¡°ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”."

    # Build user content: include the emotion JSON, optional color JSON, and a request to rewrite in influencer tone
    emotion_json = json.dumps(payload.emotion_result, ensure_ascii=False)
    color_json = json.dumps(payload.color_result, ensure_ascii=False) if payload.color_result else ''

    user_content = f"ë‹¤ìŒì€ ê°ì • ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:\n{emotion_json}\n"
    if color_json:
        user_content += f"\nì°¸ê³  í¼ìŠ¤ë„ì»¬ëŸ¬ ê²°ê³¼:\n{color_json}\n"
    # Determine salutation for emotion chain: prefer provided nickname, otherwise influencer subscriber default
    salutation = None
    try:
        subs = YOUTUBER_PROFILES.get(influencer, {}).get('subscriber_name') or []
        default_sub = subs[0] if isinstance(subs, (list, tuple)) and len(subs) > 0 else 'ì—¬ëŸ¬ë¶„'
    except Exception:
        default_sub = 'ì—¬ëŸ¬ë¶„'

    if getattr(payload, 'user_nickname', None):
        salutation = f"{payload.user_nickname}ë‹˜"
    else:
        salutation = default_sub

    # If caller marked this as a welcome prompt, instruct the model to emit a
    # short, friendly welcome message requesting an image upload (single sentence)
    # while preserving the influencer style when available.
    try:
        meta = None
        if isinstance(payload.emotion_result, dict):
            meta = payload.emotion_result.get('_meta') or payload.emotion_result.get('meta')
    except Exception:
        meta = None

    if meta and isinstance(meta, dict) and meta.get('is_welcome'):
        # Prefer including the original welcome_prompt as an example/context
        wp = (meta.get('welcome_prompt') or payload.user_text or '').strip()
        example_line = f"ì˜ˆì‹œ ìš”ì²­: {wp}" if wp else ''
        if influencer:
            user_content += f"\n(í˜¸ì¹­: {salutation})\nì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì‚¬ì§„(ì–¼êµ´ ì •ë©´) ì—…ë¡œë“œë¥¼ ìš”ì²­í•˜ëŠ” í•œ ë¬¸ì¥ í™˜ì˜ ë©”ì‹œì§€ë¥¼ {influencer}ì˜ ë§íˆ¬ë¡œ ì‘ì„±í•˜ì„¸ìš”. {example_line} ì¶œë ¥ì€ ì„¤ëª… ì—†ì´ ë‹¨ í•˜ë‚˜ì˜ JSON ê°ì²´ë¡œ, í‚¤ëŠ” 'styled_text'ë¡œ í•˜ì„¸ìš”."
        else:
            user_content += f"\n(í˜¸ì¹­: {salutation})\nì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì‚¬ì§„(ì–¼êµ´ ì •ë©´) ì—…ë¡œë“œë¥¼ ìš”ì²­í•˜ëŠ” í•œ ë¬¸ì¥ í™˜ì˜ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”. {example_line} ì¶œë ¥ì€ ì„¤ëª… ì—†ì´ ë‹¨ í•˜ë‚˜ì˜ JSON ê°ì²´ë¡œ, í‚¤ëŠ” 'styled_text'ë¡œ í•˜ì„¸ìš”."
    else:
        if influencer:
            user_content += f"\n(í˜¸ì¹­: {salutation})\nìœ„ ë‚´ìš©ì„ {influencer}ì˜ ë§íˆ¬ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½Â·ì¬ì‘ì„±í•´ì£¼ì„¸ìš”. ì¶œë ¥ì€ ì„¤ëª… ì—†ì´ ë‹¨ í•˜ë‚˜ì˜ JSON ê°ì²´ë¡œ, í‚¤ëŠ” 'styled_text'ë¡œ í•˜ì„¸ìš”."
        else:
            user_content += f"\n(í˜¸ì¹­: {salutation})\nìœ„ ë‚´ìš©ì„ ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡°ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½Â·ì¬ì‘ì„±í•´ì£¼ì„¸ìš”. ì¶œë ¥ì€ ì„¤ëª… ì—†ì´ ë‹¨ í•˜ë‚˜ì˜ JSON ê°ì²´ë¡œ, í‚¤ëŠ” 'styled_text'ë¡œ í•˜ì„¸ìš”."

    try:
        resp = shared.client.chat.completions.create(
            model=os.getenv('DEFAULT_MODEL') or 'gpt-4o-mini',
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content},
            ],
            temperature=0.6,
            max_tokens=400,
        )
    except Exception as e:
        raise HTTPException(status_code=502, detail=f'Upstream model error: {e}')

    content = None
    if resp and getattr(resp, 'choices', None):
        ch = resp.choices[0]
        if isinstance(ch, dict):
            content = ch.get('message', {}).get('content') or ch.get('text')
        else:
            content = getattr(ch.message, 'content', None) or getattr(ch, 'text', None)

    if not content:
        raise HTTPException(status_code=500, detail='Empty model response')

    parsed = _extract_json_from_text(content)
    if not parsed:
        try:
            parsed = json.loads(content)
        except Exception:
            return EmotionChainResponse(influencer=influencer, styled_text=content.strip(), raw={'model_output': content})

    styled = parsed.get('styled_text') or parsed.get('text') or parsed.get('response') or ''
    return EmotionChainResponse(influencer=influencer, styled_text=styled, raw={'model_output': parsed})
